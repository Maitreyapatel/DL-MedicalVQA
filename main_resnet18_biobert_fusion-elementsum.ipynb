{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import BertTokenizer, BertModel"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "cfg = {\n",
    "    'max_len': 128,\n",
    "    'lr': 2e-5,\n",
    "    'warmup_steps': 5,\n",
    "    'epochs': 250\n",
    "}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "class medical_dataset(Dataset):\n",
    "    def __init__(self, config=None, answer_map=None, image_path='./dataset/TrainingDataset/images/', qa_file=\"./dataset/TrainingDataset/training_qa.txt\", train=True):\n",
    "            \n",
    "        assert answer_map!=None\n",
    "        assert config!=None\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.qa_file = qa_file\n",
    "        self.config = config\n",
    "        self.train = train\n",
    "        \n",
    "        self.answer_map = answer_map\n",
    "        self.data = pd.read_csv(qa_file, sep='|', names=['imageid', 'question', 'answer'])\n",
    "           \n",
    "        # print(Counter(self.data.answer.tolist()))\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        self.tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "    def process_data(self, text, max_len):\n",
    "        text = str(text)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = max_len - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        question = self.data.question[index]\n",
    "        answer = self.data.answer[index]\n",
    "        image_idx = self.data.imageid[index]\n",
    "        \n",
    "        ## add visual feature related steps\n",
    "        visuals = Image.open(join(self.image_path, f'{image_idx}.jpg'))\n",
    "        visuals = self.transforms(visuals)\n",
    "        \n",
    "        target = torch.from_numpy(np.array([self.answer_map[answer]])).long()\n",
    "        \n",
    "        tmp = self.process_data(question, self.config['max_len'])\n",
    "        question_tokens = {\n",
    "            'ids': tmp['ids'],\n",
    "            'mask': tmp['mask'],\n",
    "        }\n",
    "        \n",
    "        return visuals, question_tokens, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# file_path = './dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_QA_pairs.txt'\n",
    "# data = pd.read_csv(file_path, sep='|', names=['imageid', 'question', 'answer'])\n",
    "# data.head()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "# answer_map = {}\n",
    "# ct = 0\n",
    "\n",
    "# for i in data.answer.unique():\n",
    "#     answer_map[i] = ct\n",
    "#     ct+=1"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# with open('./answer_map.pickle', 'wb') as handle:\n",
    "#     pickle.dump(answer_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "with open('./answer_map.pickle', 'rb') as handle:\n",
    "    answer_map = pickle.load(handle)\n",
    "    \n",
    "len(answer_map)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "333"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "TrainData = medical_dataset(config=cfg, answer_map=answer_map, image_path='./dataset/TrainingDataset/images/', qa_file='./dataset/TrainingDataset/training_qa.txt')\n",
    "ValData = medical_dataset(config=cfg, answer_map=answer_map, image_path='./dataset/VQA-Med-2021-Tasks-1-2-NewValidationSets/ImageCLEF-2021-VQA-Med-New-Validation-Images/', qa_file='./dataset/VQA-Med-2021-Tasks-1-2-NewValidationSets/VQA-Med-2021-VQAnswering-Task1-New-ValidationSet.txt', train=False)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "%%time\n",
    "a,b,c = ValData.__getitem__(0)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "CPU times: user 12 ms, sys: 9.53 ms, total: 21.6 ms\n",
      "Wall time: 38 ms\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "source": [
    "TrainDataLoader = DataLoader(TrainData, batch_size=16, shuffle=True, num_workers=4)  # num_workers=0 for windows OS\n",
    "ValDataLoader = DataLoader(ValData, batch_size=128, shuffle=False, num_workers=4)  # num_workers=0 for windows OS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "#3rd Fusion Module\n",
    "class ElementsumFusion(nn.Module):\n",
    "\n",
    "    def __init__(self, dim_v=None, dim_q=None, dim_h=512):\n",
    "        super(ElementsumFusion, self).__init__()\n",
    "        # Modules\n",
    "        self.dim_v = dim_v\n",
    "        self.dim_q = dim_q\n",
    "        self.dim_h = dim_h\n",
    "        self.dropout = 0\n",
    "        self.activation = 'relu'\n",
    "        \n",
    "        if dim_v:\n",
    "            self.linear_v = nn.Linear(dim_v, dim_h)\n",
    "        else:\n",
    "            print('Warning fusion.py: no visual embedding before fusion')\n",
    "\n",
    "        if dim_q:\n",
    "            self.linear_q = nn.Linear(dim_q, dim_h)\n",
    "        else:\n",
    "            print('Warning fusion.py: no question embedding before fusion')\n",
    "        \n",
    "    def forward(self, input_v, input_q):\n",
    "        # visual (cnn features)\n",
    "        if self.dim_v:\n",
    "            x_v = F.dropout(input_v, p=self.dropout, training=self.training)\n",
    "            x_v = self.linear_v(x_v)\n",
    "            x_v = getattr(F, self.activation)(x_v)\n",
    "        else:\n",
    "            x_v = input_v\n",
    "        # question (rnn features)\n",
    "        if self.dim_q:\n",
    "            x_q = F.dropout(input_q, p=self.dropout, training=self.training)\n",
    "            x_q = self.linear_q(x_q)\n",
    "            x_q = getattr(F, self.activation)(x_q)\n",
    "        else:\n",
    "            x_q = input_q\n",
    "        # hadamard product\n",
    "        x_mm = torch.add(x_v, 1, x_q)\n",
    "        return x_mm"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "class mednet(nn.Module):\n",
    "    def __init__(self, config, max_labels):\n",
    "        super(mednet, self).__init__()\n",
    "        self.vision = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.vision.fc.in_features\n",
    "        \n",
    "        self.vision = nn.Sequential(*list(self.vision.children())[:-1])\n",
    "        self.bert = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "        \n",
    "        print(f\"Number of vision filters: {num_ftrs}\")\n",
    "        self.fc1 = nn.Linear(512, 128)\n",
    "        self.fc2 = nn.Linear(128, max_labels)\n",
    "        \n",
    "        self.fusion = ElementsumFusion(dim_v=num_ftrs, dim_q=768, dim_h=512)\n",
    "        \n",
    "\n",
    "    def forward(self, visual=None, ids=None, mask=None):\n",
    "        vision = self.vision(visual).view((ids.shape[0], -1))\n",
    "        bert_out = self.bert(ids, mask)\n",
    "        \n",
    "        h = self.fusion(vision, bert_out.last_hidden_state[:,0])\n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.fc2(h)\n",
    "        return h\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self,\n",
    "                 patience=7,\n",
    "                 verbose=False,\n",
    "                 delta=0,\n",
    "                 path='./models/checkpoint.pt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(\n",
    "                f'EarlyStopping counter: {self.counter} out of {self.patience}'\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ],
   "outputs": [],
   "metadata": {
    "code_folding": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 trainloader,\n",
    "                 vallaoder,\n",
    "                 model_ft,\n",
    "                 writer=None,\n",
    "                 testloader=None,\n",
    "                 checkpoint_path=None,\n",
    "                 patience=10,\n",
    "                 feature_extract=True,\n",
    "                 print_itr=50,\n",
    "                 config=None):\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = vallaoder\n",
    "        self.testloader = testloader\n",
    "        \n",
    "        self.config=config\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        print(\"==\" * 10)\n",
    "        print(\"Training will be done on \", self.device)\n",
    "        print(\"==\" * 10)\n",
    "\n",
    "        self.model = model_ft        \n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model, device_ids=[0,1])\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        self.optimizer = optim.RAdam(self.model.parameters(), lr=self.config['lr'])\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
    "                                            num_warmup_steps = len(self.trainloader)*self.config['warmup_steps'], # Default value in run_glue.py\n",
    "                                            num_training_steps = len(self.trainloader)*self.config['epochs'])\n",
    "\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        self.writer = writer\n",
    "        self.print_itr = print_itr\n",
    "\n",
    "    def train(self, ep):\n",
    "        self.model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for en, (visuals, question, target) in tqdm(enumerate(self.trainloader)):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            visuals = visuals.to(self.device)\n",
    "            y = target.squeeze().to(self.device)\n",
    "            \n",
    "            ids = question['ids'].to(self.device)\n",
    "            mask = question['mask'].to(self.device)\n",
    "\n",
    "            outputs = self.model(visuals, ids, mask)\n",
    "            loss = self.criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Train Loss', running_loss, ep*len(self.trainloader) + en)\n",
    "            running_loss = 0\n",
    "            \n",
    "\n",
    "    def validate(self, ep):\n",
    "        self.model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for en, (visuals, question, target) in tqdm(enumerate(self.valloader)):\n",
    "                visuals = visuals.to(self.device)\n",
    "                y = target.squeeze().to(self.device)\n",
    "                \n",
    "                ids = question['ids'].to(self.device)\n",
    "                mask = question['mask'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(visuals, ids, mask)\n",
    "                loss = self.criterion(outputs, y)\n",
    "\n",
    "                y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "                _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "                # self.tmp_sv_ = y_pred_tags\n",
    "                \n",
    "                correct += (y_pred_tags.detach().cpu().data.numpy() == y.detach().cpu().data.numpy()).sum()\n",
    "                total += y_pred_tags.shape[0]\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        return running_loss / len(self.valloader), correct*100/total\n",
    "\n",
    "    def perform_training(self, total_epoch):\n",
    "        val_loss, acc = self.validate(0)\n",
    "\n",
    "        print(\"[Initial Validation results] Loss: {} \\t Acc: {}\".format(\n",
    "            val_loss, acc))\n",
    "\n",
    "        for i in range(total_epoch):\n",
    "            self.train(i + 1)\n",
    "            val_loss, acc = self.validate(i + 1)\n",
    "            print('[{}/{}] Loss: {} \\t Acc: {}'.format(i+1, total_epoch, val_loss, acc))\n",
    "\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Validation Loss', val_loss, (i + 1))\n",
    "                self.writer.add_scalar('Validation Acc', acc, (i + 1))\n",
    "\n",
    "            self.early_stopping(-acc, self.model)\n",
    "\n",
    "            if self.early_stopping.early_stop:\n",
    "                print(\"Early stopping\")\n",
    "                break\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "        print(\"Training finished !!\")\n",
    "        print(\"=\" * 20)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "model_ft = mednet(config=cfg, max_labels=len(answer_map))\n",
    "writer = SummaryWriter('runs/resnet18_fusion-elementsum_run_1')\n",
    "trainer = Trainer(TrainDataLoader, ValDataLoader, model_ft, writer=writer, config=cfg)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of vision filters: 512\n",
      "====================\n",
      "Training will be done on  cuda\n",
      "====================\n",
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "trainer.perform_training(cfg['epochs'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [00:04,  1.04s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Initial Validation results] Loss: 5.8221728801727295 \t Acc: 0.0\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:52,  5.33it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[1/250] Loss: 5.8135682344436646 \t Acc: 0.2\n",
      "Validation loss decreased (inf --> -0.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2/250] Loss: 5.791120648384094 \t Acc: 0.4\n",
      "Validation loss decreased (-0.200000 --> -0.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:52,  5.33it/s]\n",
      "4it [00:01,  2.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[3/250] Loss: 5.766025900840759 \t Acc: 1.0\n",
      "Validation loss decreased (-0.400000 --> -1.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[4/250] Loss: 5.720999240875244 \t Acc: 1.2\n",
      "Validation loss decreased (-1.000000 --> -1.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[5/250] Loss: 5.644358992576599 \t Acc: 2.4\n",
      "Validation loss decreased (-1.200000 --> -2.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[6/250] Loss: 5.536285042762756 \t Acc: 4.0\n",
      "Validation loss decreased (-2.400000 --> -4.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[7/250] Loss: 5.421822905540466 \t Acc: 6.0\n",
      "Validation loss decreased (-4.000000 --> -6.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[8/250] Loss: 5.314312219619751 \t Acc: 7.2\n",
      "Validation loss decreased (-6.000000 --> -7.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[9/250] Loss: 5.1628721952438354 \t Acc: 9.2\n",
      "Validation loss decreased (-7.200000 --> -9.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[10/250] Loss: 5.092556953430176 \t Acc: 7.6\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[11/250] Loss: 4.985626459121704 \t Acc: 9.4\n",
      "Validation loss decreased (-9.200000 --> -9.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[12/250] Loss: 4.868507266044617 \t Acc: 8.6\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[13/250] Loss: 4.771825432777405 \t Acc: 9.4\n",
      "Validation loss decreased (-9.400000 --> -9.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[14/250] Loss: 4.683165669441223 \t Acc: 11.6\n",
      "Validation loss decreased (-9.400000 --> -11.600000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[15/250] Loss: 4.578542709350586 \t Acc: 13.4\n",
      "Validation loss decreased (-11.600000 --> -13.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[16/250] Loss: 4.501201868057251 \t Acc: 13.2\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[17/250] Loss: 4.440851211547852 \t Acc: 14.4\n",
      "Validation loss decreased (-13.400000 --> -14.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18/250] Loss: 4.38092827796936 \t Acc: 13.2\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[19/250] Loss: 4.237519264221191 \t Acc: 16.2\n",
      "Validation loss decreased (-14.400000 --> -16.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[20/250] Loss: 4.214712858200073 \t Acc: 16.4\n",
      "Validation loss decreased (-16.200000 --> -16.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[21/250] Loss: 4.189817190170288 \t Acc: 16.2\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[22/250] Loss: 4.146097540855408 \t Acc: 16.2\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.57it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[23/250] Loss: 4.154565811157227 \t Acc: 18.4\n",
      "Validation loss decreased (-16.400000 --> -18.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[24/250] Loss: 3.9955588579177856 \t Acc: 18.0\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:52,  5.32it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[25/250] Loss: 3.997759521007538 \t Acc: 18.2\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[26/250] Loss: 3.9107438921928406 \t Acc: 19.0\n",
      "Validation loss decreased (-18.400000 --> -19.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[27/250] Loss: 3.89912086725235 \t Acc: 19.2\n",
      "Validation loss decreased (-19.000000 --> -19.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.49it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[28/250] Loss: 3.9460229873657227 \t Acc: 20.2\n",
      "Validation loss decreased (-19.200000 --> -20.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[29/250] Loss: 3.8530113101005554 \t Acc: 21.8\n",
      "Validation loss decreased (-20.200000 --> -21.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[30/250] Loss: 3.8598002195358276 \t Acc: 21.8\n",
      "Validation loss decreased (-21.800000 --> -21.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[31/250] Loss: 3.812596082687378 \t Acc: 22.2\n",
      "Validation loss decreased (-21.800000 --> -22.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[32/250] Loss: 3.751449763774872 \t Acc: 21.4\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:52,  5.32it/s]\n",
      "4it [00:01,  2.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[33/250] Loss: 3.8390117287635803 \t Acc: 21.8\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[34/250] Loss: 3.734971582889557 \t Acc: 24.4\n",
      "Validation loss decreased (-22.200000 --> -24.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[35/250] Loss: 3.7073583006858826 \t Acc: 25.0\n",
      "Validation loss decreased (-24.400000 --> -25.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[36/250] Loss: 3.6851829290390015 \t Acc: 26.0\n",
      "Validation loss decreased (-25.000000 --> -26.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[37/250] Loss: 3.63015353679657 \t Acc: 23.6\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[38/250] Loss: 3.630078971385956 \t Acc: 24.4\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[39/250] Loss: 3.607324182987213 \t Acc: 22.8\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[40/250] Loss: 3.6329208612442017 \t Acc: 24.8\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[41/250] Loss: 3.7104918360710144 \t Acc: 23.6\n",
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[42/250] Loss: 3.610133469104767 \t Acc: 24.6\n",
      "EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[43/250] Loss: 3.676137864589691 \t Acc: 24.4\n",
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[44/250] Loss: 3.7011982202529907 \t Acc: 26.0\n",
      "Validation loss decreased (-26.000000 --> -26.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[45/250] Loss: 3.5649701952934265 \t Acc: 28.4\n",
      "Validation loss decreased (-26.000000 --> -28.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.54it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[46/250] Loss: 3.5545979142189026 \t Acc: 29.8\n",
      "Validation loss decreased (-28.400000 --> -29.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.53it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[47/250] Loss: 3.5117136240005493 \t Acc: 30.0\n",
      "Validation loss decreased (-29.800000 --> -30.000000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[48/250] Loss: 3.4580332040786743 \t Acc: 30.6\n",
      "Validation loss decreased (-30.000000 --> -30.600000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[49/250] Loss: 3.5396506786346436 \t Acc: 27.4\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[50/250] Loss: 3.624606192111969 \t Acc: 27.8\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[51/250] Loss: 3.517681062221527 \t Acc: 27.8\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[52/250] Loss: 3.4448540806770325 \t Acc: 30.8\n",
      "Validation loss decreased (-30.600000 --> -30.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[53/250] Loss: 3.5209118127822876 \t Acc: 28.4\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.50it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[54/250] Loss: 3.5797603130340576 \t Acc: 30.8\n",
      "Validation loss decreased (-30.800000 --> -30.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[55/250] Loss: 3.5360729098320007 \t Acc: 32.6\n",
      "Validation loss decreased (-30.800000 --> -32.600000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[56/250] Loss: 3.510233998298645 \t Acc: 29.6\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[57/250] Loss: 3.51551616191864 \t Acc: 29.8\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[58/250] Loss: 3.5220212936401367 \t Acc: 32.4\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[59/250] Loss: 3.6147786378860474 \t Acc: 30.4\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[60/250] Loss: 3.5430420637130737 \t Acc: 28.6\n",
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[61/250] Loss: 3.644425928592682 \t Acc: 30.6\n",
      "EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.32it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[62/250] Loss: 3.4798313975334167 \t Acc: 32.0\n",
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.51it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[63/250] Loss: 3.455235242843628 \t Acc: 33.6\n",
      "Validation loss decreased (-32.600000 --> -33.600000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[64/250] Loss: 3.5509286522865295 \t Acc: 31.4\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[65/250] Loss: 3.4899246096611023 \t Acc: 32.2\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[66/250] Loss: 3.522518217563629 \t Acc: 32.8\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.56it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[67/250] Loss: 3.4503977298736572 \t Acc: 33.8\n",
      "Validation loss decreased (-33.600000 --> -33.800000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[68/250] Loss: 3.4587578177452087 \t Acc: 32.2\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[69/250] Loss: 3.5794461965560913 \t Acc: 30.4\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[70/250] Loss: 3.5695130825042725 \t Acc: 32.4\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[71/250] Loss: 3.4550111889839172 \t Acc: 33.6\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[72/250] Loss: 3.4877008199691772 \t Acc: 32.2\n",
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[73/250] Loss: 3.5596903562545776 \t Acc: 35.2\n",
      "Validation loss decreased (-33.800000 --> -35.200000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[74/250] Loss: 3.715454876422882 \t Acc: 29.0\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[75/250] Loss: 3.5673781633377075 \t Acc: 35.4\n",
      "Validation loss decreased (-35.200000 --> -35.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.55it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[76/250] Loss: 3.5713347792625427 \t Acc: 33.2\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.50it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[77/250] Loss: 3.5321478247642517 \t Acc: 34.0\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.54it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[78/250] Loss: 3.4876806139945984 \t Acc: 35.2\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[79/250] Loss: 3.7247402667999268 \t Acc: 32.2\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.58it/s]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[80/250] Loss: 3.4828875064849854 \t Acc: 36.4\n",
      "Validation loss decreased (-35.400000 --> -36.400000).  Saving model ...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[81/250] Loss: 3.4792022109031677 \t Acc: 35.4\n",
      "EarlyStopping counter: 1 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[82/250] Loss: 3.508804440498352 \t Acc: 35.0\n",
      "EarlyStopping counter: 2 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.56it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[83/250] Loss: 3.519869029521942 \t Acc: 33.8\n",
      "EarlyStopping counter: 3 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[84/250] Loss: 3.5421931743621826 \t Acc: 31.8\n",
      "EarlyStopping counter: 4 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[85/250] Loss: 3.5046932101249695 \t Acc: 36.0\n",
      "EarlyStopping counter: 5 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.51it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[86/250] Loss: 3.559581220149994 \t Acc: 33.2\n",
      "EarlyStopping counter: 6 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[87/250] Loss: 3.570066809654236 \t Acc: 33.8\n",
      "EarlyStopping counter: 7 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.30it/s]\n",
      "4it [00:01,  2.52it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[88/250] Loss: 3.520843803882599 \t Acc: 34.2\n",
      "EarlyStopping counter: 8 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.49it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[89/250] Loss: 3.5724109411239624 \t Acc: 35.2\n",
      "EarlyStopping counter: 9 out of 10\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n",
      "282it [00:53,  5.31it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[90/250] Loss: 3.5846240520477295 \t Acc: 34.8\n",
      "EarlyStopping counter: 10 out of 10\n",
      "Early stopping\n",
      "====================\n",
      "Training finished !!\n",
      "====================\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ],
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "class medical_dataset_test(Dataset):\n",
    "    def __init__(self, config=None, answer_map=None, image_path='./dataset/Task1-VQA-2021-TestSet-w-GroundTruth/VQA-500-Images/', qa_file=\"./dataset/Task1-VQA-2021-TestSet-w-GroundTruth/Task1-VQA-2021-TestSet-Questions.txt\", train=True):\n",
    "            \n",
    "        assert answer_map!=None\n",
    "        assert config!=None\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.qa_file = qa_file\n",
    "        self.config = config\n",
    "        self.train = train\n",
    "        \n",
    "        self.answer_map = answer_map\n",
    "        self.data = pd.read_csv(qa_file, sep='|', names=['imageid', 'question'])\n",
    "           \n",
    "        # print(Counter(self.data.answer.tolist()))\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        self.tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "    def process_data(self, text, max_len):\n",
    "        text = str(text)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = max_len - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        question = self.data.question[index]\n",
    "        image_idx = self.data.imageid[index]\n",
    "        \n",
    "        ## add visual feature related steps\n",
    "        visuals = Image.open(join(self.image_path, f'{image_idx}.jpg'))\n",
    "        visuals = self.transforms(visuals)\n",
    "        \n",
    "        \n",
    "        tmp = self.process_data(question, self.config['max_len'])\n",
    "        question_tokens = {\n",
    "            'ids': tmp['ids'],\n",
    "            'mask': tmp['mask'],\n",
    "        }\n",
    "        \n",
    "        return visuals, question_tokens, image_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "source": [
    "TestData = medical_dataset_test(config=cfg, answer_map=answer_map)\n",
    "TestDataLoader = DataLoader(TestData, batch_size=128, shuffle=False, num_workers=4)  # num_workers=0 for windows OS"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "source": [
    "inv_map = {v: k for k, v in answer_map.items()}"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "source": [
    "trainer.model.load_state_dict(torch.load('./models/checkpoint.pt'))\n",
    "trainer.model.eval()\n",
    "        \n",
    "imageids = []\n",
    "answers = []\n",
    "\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for en, (visuals, question, target) in tqdm(enumerate(TestDataLoader)):\n",
    "        visuals = visuals.to(trainer.device)\n",
    "\n",
    "        ids = question['ids'].to(trainer.device)\n",
    "        mask = question['mask'].to(trainer.device)\n",
    "\n",
    "        outputs = trainer.model(visuals, ids, mask)\n",
    "\n",
    "        y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "        # self.tmp_sv_ = y_pred_tags\n",
    "        \n",
    "        for i in range(visuals.shape[0]):\n",
    "            imageids.append(target[i])\n",
    "            answers.append(inv_map[int(y_pred_tags[i])])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "4it [00:01,  2.36it/s]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "source": [
    "answers[:5]"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['spine, intradural lipoma',\n",
       " 'pulmonary embolism',\n",
       " 'calcific tendinitis',\n",
       " 'transitional cell carcinoma, bladder',\n",
       " 'simple bone cyst']"
      ]
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "metadata": {
    "tags": []
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "pd.DataFrame({'imageids':imageids, 'answers':answers}).to_csv('resnet18_fusion-elementsum.txt', sep='|', index=False, header=False)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}