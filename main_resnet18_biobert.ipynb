{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22bedcab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ac28ffc-05b6-4fd7-a584-0ae24a20d07d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "261a1f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "from os import listdir, makedirs, getcwd, remove\n",
    "from os.path import isfile, join, abspath, exists, isdir, expanduser\n",
    "from scipy.io import loadmat\n",
    "from PIL import Image\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "\n",
    "\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2caa207d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.autograd as autograd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.utils.data as data\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import itertools\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets, models\n",
    "from torch import Tensor\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1a865ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "import tokenizers\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3711f483-5a00-4c36-8bf5-5467d16446fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'max_len': 128,\n",
    "    'lr': 2e-5,\n",
    "    'warmup_steps': 5,\n",
    "    'epochs': 250\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361ec734-2978-46d2-891d-6af0bd2e6b25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8d4705-76e7-413b-888e-6e9e651d2b11",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c1b29e-5c21-4331-840d-a4b9b60ac4d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bda850c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class medical_dataset(Dataset):\n",
    "    def __init__(self, config=None, answer_map=None, image_path='./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_images/', qa_file=\"./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_QA_pairs.txt\", train=True):\n",
    "            \n",
    "        assert answer_map!=None\n",
    "        assert config!=None\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.qa_file = qa_file\n",
    "        self.config = config\n",
    "        self.train = train\n",
    "        \n",
    "        self.answer_map = answer_map\n",
    "        self.data = pd.read_csv(qa_file, sep='|', names=['imageid', 'question', 'answer'])\n",
    "           \n",
    "        # print(Counter(self.data.answer.tolist()))\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        self.tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "    def process_data(self, text, max_len):\n",
    "        text = str(text)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = max_len - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        question = self.data.question[index]\n",
    "        answer = self.data.answer[index]\n",
    "        image_idx = self.data.imageid[index]\n",
    "        \n",
    "        ## add visual feature related steps\n",
    "        visuals = Image.open(join(self.image_path, f'{image_idx}.jpg'))\n",
    "        visuals = self.transforms(visuals)\n",
    "        \n",
    "        target = torch.from_numpy(np.array([self.answer_map[answer]])).long()\n",
    "        \n",
    "        tmp = self.process_data(question, self.config['max_len'])\n",
    "        question_tokens = {\n",
    "            'ids': tmp['ids'],\n",
    "            'mask': tmp['mask'],\n",
    "        }\n",
    "        \n",
    "        return visuals, question_tokens, target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87d719ac-8530-4476-b916-fa15d50180a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file_path = './dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_QA_pairs.txt'\n",
    "# data = pd.read_csv(file_path, sep='|', names=['imageid', 'question', 'answer'])\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f7e3956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# answer_map = {}\n",
    "# ct = 0\n",
    "\n",
    "# for i in data.answer.unique():\n",
    "#     answer_map[i] = ct\n",
    "#     ct+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "26648cec-3412-4e3a-8565-2e1b0c55acc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./answer_map.pickle', 'wb') as handle:\n",
    "#     pickle.dump(answer_map, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f463d0db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "332"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./answer_map.pickle', 'rb') as handle:\n",
    "    answer_map = pickle.load(handle)\n",
    "    \n",
    "len(answer_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b24d4cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainData = medical_dataset(config=cfg, answer_map=answer_map, image_path='./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_images/', qa_file='./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-TrainingSet/VQAnswering_2020_Train_QA_pairs.txt')\n",
    "ValData = medical_dataset(config=cfg, answer_map=answer_map, image_path='./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-ValidationSet/VQAnswering_2020_Val_images/', qa_file='./dataset/VQA-Med-2020-Task1-VQAnswering-TrainVal-Sets/VQAMed2020-VQAnswering-ValidationSet/VQAnswering_2020_Val_QA_Pairs.txt', train=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6f3d1708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.2 ms, sys: 0 ns, total: 31.2 ms\n",
      "Wall time: 27.3 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "a,b,c = ValData.__getitem__(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25ca53cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TrainDataLoader = DataLoader(TrainData, batch_size=16, shuffle=True, num_workers=4)  # num_workers=0 for windows OS\n",
    "ValDataLoader = DataLoader(ValData, batch_size=128, shuffle=False, num_workers=4)  # num_workers=0 for windows OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "26fcd6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class mednet(nn.Module):\n",
    "    def __init__(self, config, max_labels):\n",
    "        super(mednet, self).__init__()\n",
    "        self.vision = models.resnet18(pretrained=True)\n",
    "        num_ftrs = self.vision.fc.in_features\n",
    "        \n",
    "        self.vision = nn.Sequential(*list(self.vision.children())[:-1])\n",
    "        self.bert = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "        \n",
    "        \n",
    "        self.fc1 = nn.Linear(num_ftrs+768, 128)\n",
    "        self.fc2 = nn.Linear(128, max_labels)\n",
    "        \n",
    "\n",
    "    def forward(self, visual=None, ids=None, mask=None):\n",
    "        vision = self.vision(visual).view((ids.shape[0], -1))\n",
    "        bert_out = self.bert(ids, mask)\n",
    "        \n",
    "        h = torch.cat((vision, bert_out.last_hidden_state[:,0]), dim=1)\n",
    "        \n",
    "        h = F.relu(self.fc1(h))\n",
    "        h = self.fc2(h)\n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53dba468",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class EarlyStopping:\n",
    "    \"\"\"Early stops the training if validation loss doesn't improve after a given patience.\"\"\"\n",
    "    def __init__(self,\n",
    "                 patience=7,\n",
    "                 verbose=False,\n",
    "                 delta=0,\n",
    "                 path='./models/no_fusion/checkpoint.pt',\n",
    "                 trace_func=print):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How long to wait after last time validation loss improved.\n",
    "                            Default: 7\n",
    "            verbose (bool): If True, prints a message for each validation loss improvement. \n",
    "                            Default: False\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "            path (str): Path for the checkpoint to be saved to.\n",
    "                            Default: 'checkpoint.pt'\n",
    "            trace_func (function): trace print function.\n",
    "                            Default: print            \n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "        self.path = path\n",
    "        self.trace_func = trace_func\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            self.trace_func(\n",
    "                f'EarlyStopping counter: {self.counter} out of {self.patience}'\n",
    "            )\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "            self.counter = 0\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        '''Saves model when validation loss decrease.'''\n",
    "        if self.verbose:\n",
    "            self.trace_func(\n",
    "                f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'\n",
    "            )\n",
    "        torch.save(model.state_dict(), self.path)\n",
    "        self.val_loss_min = val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8cc3829f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trainer:\n",
    "    def __init__(self,\n",
    "                 trainloader,\n",
    "                 vallaoder,\n",
    "                 model_ft,\n",
    "                 writer=None,\n",
    "                 testloader=None,\n",
    "                 checkpoint_path=None,\n",
    "                 patience=5,\n",
    "                 feature_extract=True,\n",
    "                 print_itr=50,\n",
    "                 config=None):\n",
    "        self.trainloader = trainloader\n",
    "        self.valloader = vallaoder\n",
    "        self.testloader = testloader\n",
    "        \n",
    "        self.config=config\n",
    "\n",
    "        self.device = torch.device(\n",
    "            \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "        print(\"==\" * 10)\n",
    "        print(\"Training will be done on \", self.device)\n",
    "        print(\"==\" * 10)\n",
    "\n",
    "        self.model = model_ft        \n",
    "        if torch.cuda.device_count() > 1:\n",
    "            print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "            self.model = nn.DataParallel(self.model, device_ids=[0,1])\n",
    "        \n",
    "        self.model = self.model.to(self.device)\n",
    "        \n",
    "        \n",
    "        # Observe that all parameters are being optimized\n",
    "        self.optimizer = optim.RAdam(self.model.parameters(), lr=self.config['lr'])\n",
    "        \n",
    "        self.scheduler = get_linear_schedule_with_warmup(self.optimizer, \n",
    "                                            num_warmup_steps = len(self.trainloader)*self.config['warmup_steps'], # Default value in run_glue.py\n",
    "                                            num_training_steps = len(self.trainloader)*self.config['epochs'])\n",
    "\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.early_stopping = EarlyStopping(patience=patience, verbose=True)\n",
    "        self.writer = writer\n",
    "        self.print_itr = print_itr\n",
    "\n",
    "    def train(self, ep):\n",
    "        self.model.train()\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for en, (visuals, question, target) in tqdm(enumerate(self.trainloader)):\n",
    "            self.optimizer.zero_grad()\n",
    "            \n",
    "            visuals = visuals.to(self.device)\n",
    "            y = target.squeeze().to(self.device)\n",
    "            \n",
    "            ids = question['ids'].to(self.device)\n",
    "            mask = question['mask'].to(self.device)\n",
    "\n",
    "            outputs = self.model(visuals, ids, mask)\n",
    "            loss = self.criterion(outputs, y)\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.scheduler.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Train Loss', running_loss, ep*len(self.trainloader) + en)\n",
    "            running_loss = 0\n",
    "            \n",
    "\n",
    "    def validate(self, ep):\n",
    "        self.model.eval()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():\n",
    "            for en, (visuals, question, target) in tqdm(enumerate(self.valloader)):\n",
    "                visuals = visuals.to(self.device)\n",
    "                y = target.squeeze().to(self.device)\n",
    "                \n",
    "                ids = question['ids'].to(self.device)\n",
    "                mask = question['mask'].to(self.device)\n",
    "                \n",
    "                outputs = self.model(visuals, ids, mask)\n",
    "                loss = self.criterion(outputs, y)\n",
    "\n",
    "                y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "                _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "                # self.tmp_sv_ = y_pred_tags\n",
    "                \n",
    "                correct += (y_pred_tags.detach().cpu().data.numpy() == y.detach().cpu().data.numpy()).sum()\n",
    "                total += y_pred_tags.shape[0]\n",
    "                \n",
    "                # print statistics\n",
    "                running_loss += loss.item()\n",
    "        \n",
    "        \n",
    "        return running_loss / len(self.valloader), correct*100/total\n",
    "\n",
    "    def perform_training(self, total_epoch):\n",
    "        val_loss, acc = self.validate(0)\n",
    "\n",
    "        print(\"[Initial Validation results] Loss: {} \\t Acc: {}\".format(\n",
    "            val_loss, acc))\n",
    "\n",
    "        for i in range(total_epoch):\n",
    "            self.train(i + 1)\n",
    "            val_loss, acc = self.validate(i + 1)\n",
    "            print('[{}/{}] Loss: {} \\t Acc: {}'.format(i+1, total_epoch, val_loss, acc))\n",
    "\n",
    "            if self.writer:\n",
    "                self.writer.add_scalar('Validation Loss', val_loss, (i + 1))\n",
    "                self.writer.add_scalar('Validation Acc', acc, (i + 1))\n",
    "\n",
    "            self.early_stopping(val_loss, self.model)\n",
    "\n",
    "            # if self.early_stopping.early_stop:\n",
    "            #     print(\"Early stopping\")\n",
    "            #     break\n",
    "\n",
    "        print(\"=\" * 20)\n",
    "        print(\"Training finished !!\")\n",
    "        print(\"=\" * 20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41cf8b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================\n",
      "Training will be done on  cuda\n",
      "====================\n",
      "Let's use 2 GPUs!\n"
     ]
    }
   ],
   "source": [
    "model_ft = mednet(config=cfg, max_labels=len(answer_map))\n",
    "writer = SummaryWriter('runs/no_fusion_run_2')\n",
    "trainer = Trainer(TrainDataLoader, ValDataLoader, model_ft, writer=writer, config=cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78feeab8",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:04,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Initial Validation results] Loss: 5.837615251541138 \t Acc: 0.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/250] Loss: 5.836101531982422 \t Acc: 0.2\n",
      "Validation loss decreased (inf --> 5.836102).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/250] Loss: 5.797498106956482 \t Acc: 0.6\n",
      "Validation loss decreased (5.836102 --> 5.797498).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/250] Loss: 5.7608020305633545 \t Acc: 1.4\n",
      "Validation loss decreased (5.797498 --> 5.760802).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/250] Loss: 5.663802623748779 \t Acc: 5.4\n",
      "Validation loss decreased (5.760802 --> 5.663803).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/250] Loss: 5.524681925773621 \t Acc: 5.4\n",
      "Validation loss decreased (5.663803 --> 5.524682).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/250] Loss: 5.364600658416748 \t Acc: 6.8\n",
      "Validation loss decreased (5.524682 --> 5.364601).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/250] Loss: 5.231878638267517 \t Acc: 6.8\n",
      "Validation loss decreased (5.364601 --> 5.231879).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/250] Loss: 5.118140816688538 \t Acc: 9.8\n",
      "Validation loss decreased (5.231879 --> 5.118141).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/250] Loss: 5.0242778062820435 \t Acc: 8.8\n",
      "Validation loss decreased (5.118141 --> 5.024278).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/250] Loss: 4.892484068870544 \t Acc: 11.2\n",
      "Validation loss decreased (5.024278 --> 4.892484).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11/250] Loss: 4.81072461605072 \t Acc: 10.0\n",
      "Validation loss decreased (4.892484 --> 4.810725).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12/250] Loss: 4.740372657775879 \t Acc: 11.4\n",
      "Validation loss decreased (4.810725 --> 4.740373).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13/250] Loss: 4.640388250350952 \t Acc: 12.6\n",
      "Validation loss decreased (4.740373 --> 4.640388).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14/250] Loss: 4.580736994743347 \t Acc: 11.6\n",
      "Validation loss decreased (4.640388 --> 4.580737).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15/250] Loss: 4.495085120201111 \t Acc: 14.0\n",
      "Validation loss decreased (4.580737 --> 4.495085).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16/250] Loss: 4.457839906215668 \t Acc: 13.6\n",
      "Validation loss decreased (4.495085 --> 4.457840).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17/250] Loss: 4.4025352001190186 \t Acc: 13.8\n",
      "Validation loss decreased (4.457840 --> 4.402535).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18/250] Loss: 4.331705212593079 \t Acc: 14.8\n",
      "Validation loss decreased (4.402535 --> 4.331705).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19/250] Loss: 4.2975914478302 \t Acc: 15.2\n",
      "Validation loss decreased (4.331705 --> 4.297591).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20/250] Loss: 4.215506553649902 \t Acc: 14.2\n",
      "Validation loss decreased (4.297591 --> 4.215507).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21/250] Loss: 4.161027014255524 \t Acc: 16.2\n",
      "Validation loss decreased (4.215507 --> 4.161027).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22/250] Loss: 4.17311704158783 \t Acc: 15.6\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/250] Loss: 4.107385694980621 \t Acc: 18.0\n",
      "Validation loss decreased (4.161027 --> 4.107386).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[24/250] Loss: 4.055293619632721 \t Acc: 18.2\n",
      "Validation loss decreased (4.107386 --> 4.055294).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[25/250] Loss: 4.061221420764923 \t Acc: 16.4\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[26/250] Loss: 3.969112277030945 \t Acc: 17.8\n",
      "Validation loss decreased (4.055294 --> 3.969112).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27/250] Loss: 3.9382843375205994 \t Acc: 18.6\n",
      "Validation loss decreased (3.969112 --> 3.938284).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[28/250] Loss: 3.927073657512665 \t Acc: 19.0\n",
      "Validation loss decreased (3.938284 --> 3.927074).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[29/250] Loss: 3.898852825164795 \t Acc: 18.0\n",
      "Validation loss decreased (3.927074 --> 3.898853).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[30/250] Loss: 3.866658926010132 \t Acc: 18.6\n",
      "Validation loss decreased (3.898853 --> 3.866659).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[31/250] Loss: 3.861752688884735 \t Acc: 21.6\n",
      "Validation loss decreased (3.866659 --> 3.861753).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[32/250] Loss: 3.7956483364105225 \t Acc: 21.4\n",
      "Validation loss decreased (3.861753 --> 3.795648).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[33/250] Loss: 3.7963501811027527 \t Acc: 19.8\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[34/250] Loss: 3.7830586433410645 \t Acc: 20.8\n",
      "Validation loss decreased (3.795648 --> 3.783059).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35/250] Loss: 3.7026565074920654 \t Acc: 21.8\n",
      "Validation loss decreased (3.783059 --> 3.702657).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[36/250] Loss: 3.7331173419952393 \t Acc: 21.2\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[37/250] Loss: 3.7678977251052856 \t Acc: 19.8\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.35it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38/250] Loss: 3.6464545130729675 \t Acc: 22.2\n",
      "Validation loss decreased (3.702657 --> 3.646455).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[39/250] Loss: 3.6909760236740112 \t Acc: 23.4\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40/250] Loss: 3.620068073272705 \t Acc: 23.4\n",
      "Validation loss decreased (3.646455 --> 3.620068).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[41/250] Loss: 3.6352208256721497 \t Acc: 21.6\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[42/250] Loss: 3.6112032532691956 \t Acc: 24.4\n",
      "Validation loss decreased (3.620068 --> 3.611203).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[43/250] Loss: 3.5258325934410095 \t Acc: 25.4\n",
      "Validation loss decreased (3.611203 --> 3.525833).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[44/250] Loss: 3.592952787876129 \t Acc: 25.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[45/250] Loss: 3.5132226943969727 \t Acc: 24.2\n",
      "Validation loss decreased (3.525833 --> 3.513223).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46/250] Loss: 3.52799254655838 \t Acc: 24.8\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[47/250] Loss: 3.5883543491363525 \t Acc: 24.4\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[48/250] Loss: 3.4854727387428284 \t Acc: 24.2\n",
      "Validation loss decreased (3.513223 --> 3.485473).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[49/250] Loss: 3.516741156578064 \t Acc: 26.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50/250] Loss: 3.5203317999839783 \t Acc: 25.2\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[51/250] Loss: 3.434432327747345 \t Acc: 25.6\n",
      "Validation loss decreased (3.485473 --> 3.434432).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[52/250] Loss: 3.408302664756775 \t Acc: 27.4\n",
      "Validation loss decreased (3.434432 --> 3.408303).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[53/250] Loss: 3.406317949295044 \t Acc: 26.4\n",
      "Validation loss decreased (3.408303 --> 3.406318).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[54/250] Loss: 3.3542001843452454 \t Acc: 27.8\n",
      "Validation loss decreased (3.406318 --> 3.354200).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55/250] Loss: 3.3700140714645386 \t Acc: 29.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[56/250] Loss: 3.3648563623428345 \t Acc: 29.4\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[57/250] Loss: 3.4806090593338013 \t Acc: 27.2\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[58/250] Loss: 3.3637436628341675 \t Acc: 28.6\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59/250] Loss: 3.3100754022598267 \t Acc: 29.2\n",
      "Validation loss decreased (3.354200 --> 3.310075).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[60/250] Loss: 3.36012464761734 \t Acc: 29.8\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[61/250] Loss: 3.3694770336151123 \t Acc: 30.4\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[62/250] Loss: 3.2813875675201416 \t Acc: 30.2\n",
      "Validation loss decreased (3.310075 --> 3.281388).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63/250] Loss: 3.382315993309021 \t Acc: 29.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64/250] Loss: 3.343909740447998 \t Acc: 28.6\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[65/250] Loss: 3.359048366546631 \t Acc: 29.8\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[66/250] Loss: 3.3229116797447205 \t Acc: 29.2\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[67/250] Loss: 3.2831071615219116 \t Acc: 31.4\n",
      "EarlyStopping counter: 5 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[68/250] Loss: 3.268081247806549 \t Acc: 32.4\n",
      "Validation loss decreased (3.281388 --> 3.268081).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69/250] Loss: 3.2716123461723328 \t Acc: 35.2\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70/250] Loss: 3.2979135513305664 \t Acc: 30.6\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[71/250] Loss: 3.2898788452148438 \t Acc: 31.4\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[72/250] Loss: 3.244566261768341 \t Acc: 34.0\n",
      "Validation loss decreased (3.268081 --> 3.244566).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[73/250] Loss: 3.3067516684532166 \t Acc: 32.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[74/250] Loss: 3.3184532523155212 \t Acc: 31.0\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[75/250] Loss: 3.2438436150550842 \t Acc: 33.6\n",
      "Validation loss decreased (3.244566 --> 3.243844).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[76/250] Loss: 3.308763861656189 \t Acc: 32.0\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[77/250] Loss: 3.210522174835205 \t Acc: 33.8\n",
      "Validation loss decreased (3.243844 --> 3.210522).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.34it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[78/250] Loss: 3.3308228850364685 \t Acc: 31.8\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[79/250] Loss: 3.2909353971481323 \t Acc: 34.2\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[80/250] Loss: 3.3019753098487854 \t Acc: 31.4\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[81/250] Loss: 3.292394995689392 \t Acc: 34.8\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82/250] Loss: 3.312225580215454 \t Acc: 33.2\n",
      "EarlyStopping counter: 5 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83/250] Loss: 3.3470104932785034 \t Acc: 32.8\n",
      "EarlyStopping counter: 6 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84/250] Loss: 3.1846446990966797 \t Acc: 33.4\n",
      "Validation loss decreased (3.210522 --> 3.184645).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[85/250] Loss: 3.2632964849472046 \t Acc: 32.8\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[86/250] Loss: 3.202887177467346 \t Acc: 34.2\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[87/250] Loss: 3.3135664463043213 \t Acc: 33.8\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[88/250] Loss: 3.2068715691566467 \t Acc: 34.2\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[89/250] Loss: 3.3237234354019165 \t Acc: 31.8\n",
      "EarlyStopping counter: 5 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.32it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[90/250] Loss: 3.159863770008087 \t Acc: 35.6\n",
      "Validation loss decreased (3.184645 --> 3.159864).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[91/250] Loss: 3.301831901073456 \t Acc: 32.4\n",
      "EarlyStopping counter: 1 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[92/250] Loss: 3.215398907661438 \t Acc: 35.6\n",
      "EarlyStopping counter: 2 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[93/250] Loss: 3.2453460693359375 \t Acc: 33.8\n",
      "EarlyStopping counter: 3 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[94/250] Loss: 3.238484799861908 \t Acc: 35.2\n",
      "EarlyStopping counter: 4 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[95/250] Loss: 3.264693796634674 \t Acc: 35.0\n",
      "EarlyStopping counter: 5 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[96/250] Loss: 3.2440231442451477 \t Acc: 37.2\n",
      "EarlyStopping counter: 6 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[97/250] Loss: 3.3067097663879395 \t Acc: 34.0\n",
      "EarlyStopping counter: 7 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[98/250] Loss: 3.2965638041496277 \t Acc: 34.2\n",
      "EarlyStopping counter: 8 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[99/250] Loss: 3.284667670726776 \t Acc: 33.0\n",
      "EarlyStopping counter: 9 out of 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "250it [00:46,  5.33it/s]\n",
      "4it [00:01,  2.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100/250] Loss: 3.076765477657318 \t Acc: 36.4\n",
      "Validation loss decreased (3.159864 --> 3.076765).  Saving model ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "118it [00:22,  5.30it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_1063130/2433415335.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mperform_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epochs'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_1063130/3321393544.py\u001b[0m in \u001b[0;36mperform_training\u001b[0;34m(self, total_epoch)\u001b[0m\n\u001b[1;32m    108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 110\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    111\u001b[0m             \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[{}/{}] Loss: {} \\t Acc: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_epoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_1063130/3321393544.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, ep)\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Courses/DL/project/venv/lib/python3.8/site-packages/torch/optim/lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Courses/DL/project/venv/lib/python3.8/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Courses/DL/project/venv/lib/python3.8/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Courses/DL/project/venv/lib/python3.8/site-packages/torch/optim/radam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    116\u001b[0m                     \u001b[0mstate_steps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'step'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m             F.radam(params_with_grad,\n\u001b[0m\u001b[1;32m    119\u001b[0m                     \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m                     \u001b[0mexp_avgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Courses/DL/project/venv/lib/python3.8/site-packages/torch/optim/_functional.py\u001b[0m in \u001b[0;36mradam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, state_steps, beta1, beta2, lr, weight_decay, eps)\u001b[0m\n\u001b[1;32m    435\u001b[0m         \u001b[0;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0mexp_avg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m         \u001b[0mexp_avg_sq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m         \u001b[0;31m# correcting bias for the first moving moment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.perform_training(cfg['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3183bca8-0011-4378-808e-cf5b1d702914",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4e06b0d-0629-4235-a6ea-2fbb7f01f580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "470754e3-c793-4966-b3e0-c420bc9351f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class medical_dataset_test(Dataset):\n",
    "    def __init__(self, config=None, answer_map=None, image_path='./dataset/Task1-VQA-2021-TestSet-w-GroundTruth/VQA-500-Images/', qa_file=\"./dataset/Task1-VQA-2021-TestSet-w-GroundTruth/Task1-VQA-2021-TestSet-Questions.txt\", train=True):\n",
    "            \n",
    "        assert answer_map!=None\n",
    "        assert config!=None\n",
    "        \n",
    "        self.image_path = image_path\n",
    "        self.qa_file = qa_file\n",
    "        self.config = config\n",
    "        self.train = train\n",
    "        \n",
    "        self.answer_map = answer_map\n",
    "        self.data = pd.read_csv(qa_file, sep='|', names=['imageid', 'question'])\n",
    "           \n",
    "        # print(Counter(self.data.answer.tolist()))\n",
    "        \n",
    "        self.transforms = transforms.Compose([\n",
    "                                transforms.RandomResizedCrop(224),\n",
    "                                transforms.ToTensor(),\n",
    "                                transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "                            ])\n",
    "        self.tokenizer = tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")\n",
    "\n",
    "    def process_data(self, text, max_len):\n",
    "        text = str(text)\n",
    "\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            None,\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_len,\n",
    "            truncation=True\n",
    "        )\n",
    "        ids = inputs[\"input_ids\"]\n",
    "        mask = inputs[\"attention_mask\"]\n",
    "        \n",
    "        padding_length = max_len - len(ids)\n",
    "        \n",
    "        ids = ids + ([0] * padding_length)\n",
    "        mask = mask + ([0] * padding_length)\n",
    "        \n",
    "        return {\n",
    "            'ids': torch.tensor(ids, dtype=torch.long),\n",
    "            'mask': torch.tensor(mask, dtype=torch.long),\n",
    "        }\n",
    "    \n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        question = self.data.question[index]\n",
    "        image_idx = self.data.imageid[index]\n",
    "        \n",
    "        ## add visual feature related steps\n",
    "        visuals = Image.open(join(self.image_path, f'{image_idx}.jpg'))\n",
    "        visuals = self.transforms(visuals)\n",
    "        \n",
    "        \n",
    "        tmp = self.process_data(question, self.config['max_len'])\n",
    "        question_tokens = {\n",
    "            'ids': tmp['ids'],\n",
    "            'mask': tmp['mask'],\n",
    "        }\n",
    "        \n",
    "        return visuals, question_tokens, image_idx\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d793c153-4083-43b4-8cac-8c3bf7f13d75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b1cd05-215d-4b60-aa47-3cb3affbe59d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7e245c4-940a-4421-8efd-15db84833b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "TestData = medical_dataset_test(config=cfg, answer_map=answer_map)\n",
    "TestDataLoader = DataLoader(TestData, batch_size=128, shuffle=False, num_workers=4)  # num_workers=0 for windows OS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e6650d0-27b8-4da5-91a8-cfa402e3b481",
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_map = {v: k for k, v in answer_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "397f6734-52b5-4eae-b698-9872b3290941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:01,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "trainer.model.eval()\n",
    "        \n",
    "imageids = []\n",
    "answers = []\n",
    "\n",
    "running_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for en, (visuals, question, target) in tqdm(enumerate(TestDataLoader)):\n",
    "        visuals = visuals.to(trainer.device)\n",
    "\n",
    "        ids = question['ids'].to(trainer.device)\n",
    "        mask = question['mask'].to(trainer.device)\n",
    "\n",
    "        outputs = trainer.model(visuals, ids, mask)\n",
    "\n",
    "        y_pred_softmax = torch.log_softmax(outputs, dim = 1)\n",
    "        _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)\n",
    "        # self.tmp_sv_ = y_pred_tags\n",
    "        \n",
    "        for i in range(visuals.shape[0]):\n",
    "            imageids.append(target[i])\n",
    "            answers.append(inv_map[int(y_pred_tags[i])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7fbfb9bc-ce07-471c-a606-27cb6becc535",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['femoral neck stress fractures',\n",
       " 'pulmonary embolism',\n",
       " 'aortic dissection',\n",
       " 'tophaceous gout',\n",
       " 'traumatic transient lateral patellar dislocation.']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "21062d97-e63f-483d-afbf-f81e96df9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame({'imageids':imageids, 'answers':answers}).to_csv('no_fusion.txt', sep='|', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6a73f867-d4db-413c-8460-4628db4b339f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1d373433-f40c-4aa0-956a-b988db8e71f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageid</th>\n",
       "      <th>ans1</th>\n",
       "      <th>ans2</th>\n",
       "      <th>ans3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synpic42072</td>\n",
       "      <td>avascular necrosis</td>\n",
       "      <td>extensive degenerative changes on the bilatera...</td>\n",
       "      <td>Avascular Necrosis of femoral heads bilaterall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synpic37231</td>\n",
       "      <td>pulmonary embolism</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synpic51484</td>\n",
       "      <td>osteopoikilosis</td>\n",
       "      <td>osteosclerotic lesions</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synpic15699</td>\n",
       "      <td>takayasu arteritis</td>\n",
       "      <td>multifocal stenosis of the great vessels and b...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synpic33852</td>\n",
       "      <td>acl injury</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       imageid                ans1  \\\n",
       "0  synpic42072  avascular necrosis   \n",
       "1  synpic37231  pulmonary embolism   \n",
       "2  synpic51484     osteopoikilosis   \n",
       "3  synpic15699  takayasu arteritis   \n",
       "4  synpic33852          acl injury   \n",
       "\n",
       "                                                ans2  \\\n",
       "0  extensive degenerative changes on the bilatera...   \n",
       "1                                                NaN   \n",
       "2                             osteosclerotic lesions   \n",
       "3  multifocal stenosis of the great vessels and b...   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                ans3  \n",
       "0  Avascular Necrosis of femoral heads bilaterall...  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "7756a418-7915-49a1-a0a7-ae9012672743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20.4\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "35358581-68e8-48f7-aeb0-29594ef9f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "500it [00:00, 1726.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05659260141742961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bleu_score = []\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "for en, idx in tqdm(enumerate(imageids)):\n",
    "    tmp_ = reference_data[reference_data.imageid==idx].reset_index()\n",
    "    assert len(tmp_)==1\n",
    "    \n",
    "    candidate = word_tokenize(str(answers[en]).strip().lower())\n",
    "    w_ = [tmp_.ans1[0], tmp_.ans2[0], tmp_.ans3[0]]\n",
    "    \n",
    "    reference = [word_tokenize(str(w).strip().lower()) for w in w_]\n",
    "    bleu_score.append(sentence_bleu(reference, candidate))\n",
    "        \n",
    "print(np.mean(bleu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39090a4-56b4-4ec3-b060-d02c534c1ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
