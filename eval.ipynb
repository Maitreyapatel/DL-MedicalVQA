{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adf96fd8-d4af-47d1-a7ce-3c8cd998f893",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2712d88b-d6c0-4fa2-9b01-86b1917e45f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_data = pd.read_csv('./VQA-Med-2021/Task1-VQA-2021-TestSet-w-GroundTruth/Task1-VQA-2021-TestSet-ReferenceAnswers.txt',sep='|', names=['imageid', 'ans1', 'ans2', 'ans3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15468fde-926e-4342-82a0-f34b88cbc8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imageids</th>\n",
       "      <th>answers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>synpic42072</td>\n",
       "      <td>aortic coarctation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>synpic37231</td>\n",
       "      <td>aberrant right subclavian artery (arsa)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>synpic51484</td>\n",
       "      <td>scaphoid fracture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>synpic15699</td>\n",
       "      <td>common carotid occlusion, collateral reconstit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>synpic33852</td>\n",
       "      <td>traumatic transient lateral patellar dislocation.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      imageids                                            answers\n",
       "0  synpic42072                                 aortic coarctation\n",
       "1  synpic37231            aberrant right subclavian artery (arsa)\n",
       "2  synpic51484                                  scaphoid fracture\n",
       "3  synpic15699  common carotid occlusion, collateral reconstit...\n",
       "4  synpic33852  traumatic transient lateral patellar dislocation."
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pd.read_csv('./vgg16_fusion.txt', sep='|', names=['imageids', 'answers'])\n",
    "predictions.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "24707cb0-3c3d-49a4-b5ef-1e99258b4b37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 21.4\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "gt_answers = []\n",
    "pred_answers = []\n",
    "\n",
    "for en, idx in enumerate(predictions.imageids.tolist()):\n",
    "    tmp_ = reference_data[reference_data.imageid==idx].reset_index()\n",
    "    assert len(tmp_)==1\n",
    "    \n",
    "    pred_answers.append(predictions.answers[en].strip())\n",
    "    if predictions.answers[en].strip()==tmp_.ans1[0]:\n",
    "        gt_answers.append(tmp_.ans1[0])\n",
    "    elif predictions.answers[en].strip()==tmp_.ans2[0]:\n",
    "        gt_answers.append(tmp_.ans2[0])\n",
    "    elif predictions.answers[en].strip()==tmp_.ans3[0]:\n",
    "        gt_answers.append(tmp_.ans3[0])\n",
    "    else:\n",
    "        gt_answers.append(tmp_.ans1[0])\n",
    "    if predictions.answers[en].strip()==tmp_.ans1[0] or predictions.answers[en]==tmp_.ans2[0] or predictions.answers[en]==tmp_.ans3[0]:\n",
    "        correct+=1\n",
    "\n",
    "print(\"Test accuracy:\", correct*100/len(predictions.imageids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ba6a28a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.214"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "f1_score(gt_answers, pred_answers, average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a1ac688-34c2-4f97-bfd1-031974448ddf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/home/maitreya/Courses/DL/project/venv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 2-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/maitreya/Courses/DL/project/venv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 3-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "/home/maitreya/Courses/DL/project/venv/lib/python3.8/site-packages/nltk/translate/bleu_score.py:515: UserWarning: \n",
      "The hypothesis contains 0 counts of 4-gram overlaps.\n",
      "Therefore the BLEU score evaluates to 0, independently of\n",
      "how many N-gram overlaps of lower order it contains.\n",
      "Consider using lower n-gram order or use SmoothingFunction()\n",
      "  warnings.warn(_msg)\n",
      "500it [00:00, 1199.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bleu score: 0.05328906893520416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bleu_score = []\n",
    "\n",
    "smoothie = SmoothingFunction().method0\n",
    "stops = set(stopwords.words(\"english\"))\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "    \n",
    "\n",
    "    \n",
    "for en, idx in tqdm(enumerate(predictions.imageids)):\n",
    "    tmp_ = reference_data[reference_data.imageid==idx].reset_index()\n",
    "    assert len(tmp_)==1\n",
    "    \n",
    "    \n",
    "    \n",
    "    candidate = [stemmer.stem(w.lower()) for w in word_tokenize(str(predictions.answers[en])) if w not in stops]\n",
    "    w_ = [str(tmp_.ans1[0]), str(tmp_.ans2[0]), str(tmp_.ans3[0])]\n",
    "    \n",
    "    reference = []\n",
    "    for tw in w_:\n",
    "        reference.append([stemmer.stem(w.lower()) for w in word_tokenize(str(tw)) if w not in stops])\n",
    "    \n",
    "    if len(candidate)==0 and len(reference[0])==0:\n",
    "        tmp_score = 1\n",
    "    else:\n",
    "        tmp_score = sentence_bleu(reference, candidate, smoothing_function=smoothie)\n",
    "    bleu_score.append(tmp_score)\n",
    "        \n",
    "print(\"Bleu score:\", np.mean(bleu_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9142751d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27a755d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
